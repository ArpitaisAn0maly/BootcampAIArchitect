{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Chat Completion using Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview  \n",
    "\n",
    "For more detailed examples, refer to the official [Azure OpenAI Chat Completion Documentation.](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import helper libraries and instantiate credentials and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=r'C:\\Users\\arpitaparmar\\OneDrive - Microsoft\\Documents\\bootcamp\\local.env',override=True)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"GPT4_AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"GPT4_AZURE_OPENAI_KEY\"),  \n",
    "  # api_version=\"2024-02-15-preview\",\n",
    "  api_version=\"2024-05-01-preview\"\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = os.getenv('GPT4_DEPLOYMENT_NAME') # model = \"deployment_name\"\n",
    "azureendpoint=os.getenv('GPT4_AZURE_OPENAI_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4mini\n",
      "https://aoai-aparmar-1.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "#Make sure variables are importaed correctly\n",
    "\n",
    "print(CHAT_COMPLETIONS_MODEL)\n",
    "print(azureendpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Chat Completion\n",
    "\n",
    "Each message should have a role (either \"system\", \"user\", or \"assistant\") and content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As of October 2023, the president of the United States is Joe Biden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: Who is president of USA?\n",
    "A:\"\"\"\n",
    "message_text = [{\"role\":\"system\",\"content\":prompt}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model = CHAT_COMPLETIONS_MODEL,\n",
    "  messages = message_text,\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n",
    "message_text.append({\"role\":\"assistant\",\"content\":response.choices[0].message.content})\n",
    "print(\"\\n\" + response.choices[0].message.content + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Customer Feedback\n",
    "This example demonstrates how to use the OpenAI Chat Completion feature with prompt engineering to analyze customer feedback. \\\n",
    "The task is to determine whether the provided feedback is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first feedback is negative, while the second feedback is positive.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Decide whether the following customer feedback is positive or negative.\n",
    "\n",
    "Q: I was disappointed with the quality of the product. It was very cheaply made and did not meet my expectations at all.\n",
    "Q: I was happy with this product, it is well made and great quality for the price.\n",
    "\"\"\"\n",
    "\n",
    "message_text = [{\"role\":\"system\",\"content\":prompt}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model = CHAT_COMPLETIONS_MODEL,\n",
    "  messages = message_text,\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting PII (Personally Identifiable Information) Data\n",
    "\n",
    "\n",
    "This example demonstrates how to use the OpenAI Chat Completion feature with prompt engineering to extract Personally Identifiable Information (PII) from a given text. \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following personally identifiable information (PII) can be extracted from the statement:\\n\\n1. Full name: John Doe\\n2. Age: 35 years old\\n3. Address: 21 Main Street, New York, NY\\n4. Occupation: Software engineer\\n5. Employer: Microsoft\\n6. Spouse's name: Jane Doe\\n7. Number of children: Two children\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"List all PII data from following statement:\n",
    "John Doe is a 35-year old man and he lives at 21 Main Street, New York, NY. He is a software engineer and he works at Microsft. He has a wife named Jane Doe and they have two children\n",
    "\"\"\"\n",
    "\n",
    "message_text = [{\"role\":\"system\",\"content\":prompt}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model = CHAT_COMPLETIONS_MODEL,\n",
    "  messages = message_text,\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
